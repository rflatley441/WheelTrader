{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import requests\n",
    "import QuantLib as ql\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import differential_evolution\n",
    "import concurrent.futures\n",
    "from tradingview_screener import Query, col\n",
    "import rookiepy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from gbm_optimizer import optimize_gbm, gbm\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"config.json\", \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "api_key = config.get(\"api_key\")\n",
    "secret_key = config.get(\"secret_key\")\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "our_picks = [\"AAPL\", \"AMD\", \"CHWY\", \"IBIT\", \"ASO\", \"GOOGL\"]\n",
    "our_picks=[\"VZ\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "NASDAQ = pd.read_csv('Indexes/NASDAQ.csv')\n",
    "DOWJ = pd.read_csv('Indexes/DOWJ.csv')\n",
    "SP = pd.read_csv('Indexes/S&P500.csv')\n",
    "\n",
    "def clean_data(df):\n",
    "    df = df[['Company', 'Symbol']]\n",
    "    df = pd.DataFrame(df).dropna()\n",
    "    return df\n",
    "\n",
    "NASDAQ = clean_data(NASDAQ)\n",
    "DOWJ = clean_data(DOWJ)\n",
    "SP = clean_data(SP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def screen_stocks():\n",
    "    # Get cookies for TradingView session\n",
    "    cookies = rookiepy.to_cookiejar(rookiepy.chrome(['.tradingview.com']))\n",
    "    \n",
    "    _, df = Query().select('close','change', 'Perf.3M').where(\n",
    "        col('close').between(20, 55),\n",
    "        col('change').between(-4,-2),\n",
    "        col('Perf.3M') > 0,\n",
    "        col('exchange').isin(['AMEX', 'CBOE', 'NASDAQ', 'NYSE']),\n",
    "\n",
    "        ).limit(1000).get_scanner_data(cookies=cookies)\n",
    "    \n",
    "    df[['exchange', 'ticker']] = df['ticker'].str.split(':', expand=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_rolling_price_change_avg(ticker: str, days: int):\n",
    "    try:\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days+10)\n",
    "        \n",
    "        data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        \n",
    "        if data.empty:\n",
    "            return None, None\n",
    "        \n",
    "        data = data.sort_index()\n",
    "        current_price = get_current_stock_price(ticker)\n",
    "\n",
    "        data['Price_Change'] = ((current_price - data['Close'].shift(1)) / data['Close'].shift(1)) * 100\n",
    "\n",
    "        rolling_avg = data['Price_Change'].rolling(window=min(days, len(data))).mean().iloc[-1]\n",
    "\n",
    "        return rolling_avg\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for ticker {ticker}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def get_current_stock_price(symbol: str):\n",
    "\n",
    "    url = \"https://data.alpaca.markets/v2/stocks/trades/latest\"\n",
    "\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"APCA-API-KEY-ID\": api_key,\n",
    "        \"APCA-API-SECRET-KEY\": secret_key,\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"symbols\": symbol,  \n",
    "        \"feed\": \"iex\" \n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        response.raise_for_status()  \n",
    "\n",
    "        data = response.json()\n",
    "        return data.get(\"trades\", {}).get(symbol, {}).get(\"p\") \n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching stock price: {e}\")\n",
    "\n",
    "\n",
    "def get_option_chain(api_key: str, secret_key: str, ticker: str, expiration_date: datetime):\n",
    "    expiration_str = expiration_date.strftime(\"%Y-%m-%d\")  # Convert datetime to string\n",
    "    \n",
    "    url = f\"https://data.alpaca.markets/v1beta1/options/snapshots/{ticker}?feed=indicative&limit=100&expiration_date={expiration_str}\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"APCA-API-KEY-ID\": api_key,\n",
    "        \"APCA-API-SECRET-KEY\": secret_key,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        option_chain = data.get(\"snapshots\", {})\n",
    "\n",
    "        if not option_chain:\n",
    "            return None\n",
    "\n",
    "        parsed_data = []\n",
    "        for symbol, details in option_chain.items():\n",
    "            expiration_start = len(symbol) - 15\n",
    "            option_type = \"Call\" if symbol[expiration_start+6] == \"C\" else \"Put\"\n",
    "            strike_price = int(symbol[expiration_start+7:]) / 1000  \n",
    "\n",
    "            greeks = details.get(\"greeks\", {}) or {}\n",
    "            latest_quote = details.get(\"latestQuote\", {})\n",
    "\n",
    "            parsed_data.append({\n",
    "                \"symbol\": ticker,\n",
    "                \"expiration_date\": expiration_str,  # Use the formatted string\n",
    "                \"option_type\": option_type,\n",
    "                \"strike_price\": strike_price,\n",
    "                \"delta\": greeks.get(\"delta\"),\n",
    "                \"gamma\": greeks.get(\"gamma\"),\n",
    "                \"rho\": greeks.get(\"rho\"),\n",
    "                \"theta\": greeks.get(\"theta\"),\n",
    "                \"vega\": greeks.get(\"vega\"),\n",
    "                \"implied_volatility\": details.get(\"impliedVolatility\"),\n",
    "                \"ask_price\": latest_quote.get(\"ap\"),\n",
    "                \"ask_size\": latest_quote.get(\"as\"),\n",
    "                \"bid_price\": latest_quote.get(\"bp\"),\n",
    "                \"bid_size\": latest_quote.get(\"bs\"),\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(parsed_data)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching option chain: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "def compute_score(contracts):\n",
    "    \"\"\"Compute the weighted score for contracts using normalized values.\"\"\"\n",
    "    temp_contracts = contracts.copy()\n",
    "    \n",
    "    robust_scaler = RobustScaler()\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    temp_contracts[['profitability_likelihood', 'return_percent', 'sharpe_ratio']] = scaler.fit_transform(\n",
    "        temp_contracts[['profitability_likelihood', 'return_percent', 'sharpe_ratio']]\n",
    "    )\n",
    "    \n",
    "    temp_contracts['score'] = (\n",
    "        0.50 * temp_contracts['profitability_likelihood'] +\n",
    "        0.25 * temp_contracts['return_percent'] +\n",
    "        0.25 * temp_contracts['sharpe_ratio']\n",
    "    )\n",
    "    \n",
    "    contracts['score'] = temp_contracts['score']\n",
    "    \n",
    "    return contracts\n",
    "\n",
    "def select_optimal_contract(contracts):\n",
    "    \"\"\"Select the contract with the highest weighted score while keeping original values.\"\"\"\n",
    "    contracts = compute_score(contracts)\n",
    "    contracts = contracts.sort_values(by='score', ascending=False)\n",
    "    return contracts\n",
    "\n",
    "def audit_contracts(expiration_date: datetime):\n",
    "    # t-bill 3-month rate: 4.19%, inflation rate: 2.9% -> scaled to weekly\n",
    "    risk_free_rate = (((1 + 0.0419) / (1 + 0.029)) ** (1/52) - 1) * 100\n",
    "    daily_risk_free_rate = (1 + risk_free_rate / 100) ** (1/5) - 1  # Assuming 5 business days per week\n",
    "\n",
    "    # gbm parameters\n",
    "    simulation_attempts = 500\n",
    "    optimizer_training_period = \"1y\"\n",
    "    bin_length = 18\n",
    "    days_to_expiration = np.busday_count(datetime.today().date(), expiration_date.date())\n",
    "\n",
    "\n",
    "    all_options = pd.DataFrame(columns=[\n",
    "        'symbol', 'expiration_date', 'option_type', 'strike_price', 'delta', \n",
    "        'gamma', 'rho', 'theta', 'vega', 'implied_volatility', 'ask_price', \n",
    "        'ask_size', 'bid_price', 'bid_size'\n",
    "    ])\n",
    "    \n",
    "    # stock screening\n",
    "    canidates = screen_stocks()['ticker'].to_list()\n",
    "    canidates.extend(our_picks)    \n",
    "    print(canidates)\n",
    "\n",
    "    for symbol in canidates:\n",
    "        print(f\"Evaluating {symbol}\")\n",
    "        option_chain = get_option_chain(api_key=api_key, secret_key=secret_key, ticker=symbol, expiration_date=expiration_date)\n",
    "\n",
    "        if option_chain is None or option_chain.empty:\n",
    "            continue \n",
    "        \n",
    "        put_chain = option_chain[\n",
    "            (option_chain['option_type'] == 'Put') & (option_chain['rho'].notna())\n",
    "        ].sort_values(by='strike_price', ascending=True)\n",
    "\n",
    "        price = get_current_stock_price(symbol)\n",
    "        optimized_mu, optimized_sigma = optimize_gbm(symbol=symbol, training_period=optimizer_training_period, bin_length=bin_length)\n",
    "\n",
    "        profitability_chances = []\n",
    "        percent_returns = []\n",
    "\n",
    "        for index, contract in put_chain.iterrows():\n",
    "            count = 0\n",
    "            strike_price = contract['strike_price']\n",
    "            simulated_returns = []\n",
    "\n",
    "            \n",
    "            premium_collected = (contract['bid_price'] + contract['ask_price']) / 2   \n",
    "\n",
    "            for _ in range(simulation_attempts):\n",
    "                prices = gbm(\n",
    "                    s0=price, mu=optimized_mu, sigma=optimized_sigma, \n",
    "                    deltaT=days_to_expiration, \n",
    "                    dt=1\n",
    "                )\n",
    "\n",
    "                if prices[-1] > strike_price:\n",
    "                    count += 1\n",
    "                    simulated_return = (premium_collected / strike_price) * 100  \n",
    "                    simulated_returns.append(simulated_return)\n",
    "                else:\n",
    "                    simulated_return = 0\n",
    "                    simulated_returns.append(simulated_return)\n",
    "\n",
    "\n",
    "            \n",
    "            profitability_chance = (count / simulation_attempts) * 100\n",
    "            percent_return = (premium_collected / strike_price) * 100\n",
    "            avg_return = np.mean(simulated_returns) # for sharpe ratio\n",
    "            return_std = np.std(simulated_returns, ddof=1)  # for sharpe ratio\n",
    "\n",
    "            put_chain.at[index, 'profitability_likelihood'] = profitability_chance\n",
    "            put_chain.at[index, 'return_percent'] = percent_return\n",
    "            put_chain.at[index, 'current_price'] = price\n",
    "            put_chain.at[index, 'fill_price'] = premium_collected\n",
    "\n",
    "            if put_chain['return_percent'].std() != 0:\n",
    "                put_chain.at[index, 'sharpe_ratio'] = ((avg_return - daily_risk_free_rate * days_to_expiration) / return_std) * np.sqrt(252 / days_to_expiration)\n",
    "            else:\n",
    "                put_chain.at[index, 'sharpe_ratio'] = 0  \n",
    "\n",
    "        all_options = pd.concat([all_options, put_chain], ignore_index=True, copy=False)\n",
    "\n",
    "    return all_options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OKLO', 'HIMS', 'NNE', 'KMI', 'BKR', 'NTR', 'NVD', 'AOSL', 'ERJ', 'GEO', 'NWS', 'GRAL', 'RDW', 'WES', 'OTEX', 'VCYT', 'HESM', 'FLNG', 'QMCO', 'SNN', 'TECX', 'GHM', 'ODD', 'SEI', 'PRDO', 'XMTR', 'TARK', 'QDEL', 'EXOD', 'INGM', 'REPX', 'HSTM', 'OCS', 'RM', 'ROBN', 'TESL', 'GRDN', 'NGS', 'GBLI', 'UNB', 'CNFRZ', 'CARU', 'VZ']\n",
      "Evaluating OKLO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating HIMS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/90/x6spqd2j4cbb38yrckqjm8840000gn/T/ipykernel_5442/766684614.py:225: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_options = pd.concat([all_options, put_chain], ignore_index=True, copy=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NNE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating KMI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/90/x6spqd2j4cbb38yrckqjm8840000gn/T/ipykernel_5442/766684614.py:221: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  put_chain.at[index, 'sharpe_ratio'] = ((avg_return - daily_risk_free_rate * days_to_expiration) / return_std) * np.sqrt(252 / days_to_expiration)\n",
      "/var/folders/90/x6spqd2j4cbb38yrckqjm8840000gn/T/ipykernel_5442/766684614.py:221: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  put_chain.at[index, 'sharpe_ratio'] = ((avg_return - daily_risk_free_rate * days_to_expiration) / return_std) * np.sqrt(252 / days_to_expiration)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BKR\n",
      "Evaluating NTR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/90/x6spqd2j4cbb38yrckqjm8840000gn/T/ipykernel_5442/766684614.py:221: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  put_chain.at[index, 'sharpe_ratio'] = ((avg_return - daily_risk_free_rate * days_to_expiration) / return_std) * np.sqrt(252 / days_to_expiration)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NVD\n",
      "Evaluating AOSL\n",
      "Evaluating ERJ\n",
      "Evaluating GEO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NWS\n",
      "Evaluating GRAL\n",
      "Evaluating RDW\n",
      "Evaluating WES\n",
      "Evaluating OTEX\n",
      "Evaluating VCYT\n",
      "Evaluating HESM\n",
      "Evaluating FLNG\n",
      "Evaluating QMCO\n",
      "Evaluating SNN\n",
      "Evaluating TECX\n",
      "Evaluating GHM\n",
      "Evaluating ODD\n",
      "Evaluating SEI\n",
      "Evaluating PRDO\n",
      "Evaluating XMTR\n",
      "Evaluating TARK\n",
      "Evaluating QDEL\n",
      "Evaluating EXOD\n",
      "Evaluating INGM\n",
      "Evaluating REPX\n",
      "Evaluating HSTM\n",
      "Evaluating OCS\n",
      "Evaluating RM\n",
      "Evaluating ROBN\n",
      "Evaluating TESL\n",
      "Evaluating GRDN\n",
      "Evaluating NGS\n",
      "Evaluating GBLI\n",
      "Evaluating UNB\n",
      "Evaluating CNFRZ\n",
      "Evaluating CARU\n",
      "Evaluating VZ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "/var/folders/90/x6spqd2j4cbb38yrckqjm8840000gn/T/ipykernel_5442/766684614.py:221: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  put_chain.at[index, 'sharpe_ratio'] = ((avg_return - daily_risk_free_rate * days_to_expiration) / return_std) * np.sqrt(252 / days_to_expiration)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "priced_contracts = audit_contracts(expiration_date = datetime(year=2025, month=2, day=14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m contracts \u001b[38;5;241m=\u001b[39m \u001b[43mselect_optimal_contract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpriced_contracts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mlen\u001b[39m(contracts))\n\u001b[1;32m      3\u001b[0m display(contracts)\n",
      "Cell \u001b[0;32mIn[107], line 141\u001b[0m, in \u001b[0;36mselect_optimal_contract\u001b[0;34m(contracts)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect_optimal_contract\u001b[39m(contracts):\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Select the contract with the highest weighted score while keeping original values.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     contracts \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontracts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     contracts \u001b[38;5;241m=\u001b[39m contracts\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m contracts\n",
      "Cell \u001b[0;32mIn[107], line 125\u001b[0m, in \u001b[0;36mcompute_score\u001b[0;34m(contracts)\u001b[0m\n\u001b[1;32m    122\u001b[0m temp_contracts \u001b[38;5;241m=\u001b[39m contracts\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    124\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[0;32m--> 125\u001b[0m temp_contracts[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofitability_likelihood\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_percent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msharpe_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp_contracts\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprofitability_likelihood\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreturn_percent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msharpe_ratio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m temp_contracts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;241m0.50\u001b[39m \u001b[38;5;241m*\u001b[39m temp_contracts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofitability_likelihood\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;241m0.25\u001b[39m \u001b[38;5;241m*\u001b[39m temp_contracts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_percent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;241m0.25\u001b[39m \u001b[38;5;241m*\u001b[39m temp_contracts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msharpe_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    135\u001b[0m contracts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m temp_contracts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1084\u001b[0m             (\n\u001b[1;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1094\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:450\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:490\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    487\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m    489\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 490\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m data_min \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m    498\u001b[0m data_max \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/utils/validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1061\u001b[0m     )\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/utils/validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.11/site-packages/sklearn/utils/validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    171\u001b[0m     )\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "contracts = select_optimal_contract(priced_contracts)\n",
    "print('length',len(contracts))\n",
    "display(contracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- Figure out way to normalize stock price, whether that is min max of the range of the price(shoudl help optimizer\\n- Find better metric for optimizer\\n- Try binning, so like get past 10 years of AAPL, seperate into bins of 20 or n trading days, train optimzer on each one. Then the hyperparameters can be weighted to have more bias towards more recent bins\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "\"\"\"\n",
    "- Figure out way to normalize stock price, whether that is min max of the range of the price(shoudl help optimizer\n",
    "- Find better metric for optimizer\n",
    "- Try binning, so like get past 10 years of AAPL, seperate into bins of 20 or n trading days, train optimzer on each one. Then the hyperparameters can be weighted to have more bias towards more recent bins\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archive\n",
    "\n",
    "\n",
    "# def gbm(s0, mu, sigma, deltaT, dt):\n",
    "#     \"\"\"\n",
    "#     Models a stock price S(t) using the Wiener process W(t) as\n",
    "#     `S(t) = S(0).exp{(mu-(sigma^2/2).t)+sigma.W(t)}`\n",
    "    \n",
    "#     Arguments:\n",
    "#         s0: Initial stock price, default 100\n",
    "#         mu: 'Drift' of the stock (upwards or downwards), default 0.2\n",
    "#         sigma: 'Volatility' of the stock, default 0.68\n",
    "#         deltaT: The time period for which the future prices are computed, default 52 (as in 52 weeks)\n",
    "#         dt: The granularity of the time-period, default 0.1\n",
    "    \n",
    "#     Returns:\n",
    "#         time_vector: array of time steps\n",
    "#         s: array with the simulated stock prices over the time-period deltaT\n",
    "#     \"\"\"\n",
    "#     n_step = int(deltaT / dt)  # Number of time steps\n",
    "#     time_vector = np.linspace(0, deltaT, num=n_step)  # Time vector\n",
    "    \n",
    "#     # Wiener process: cumulative sum of random normal increments\n",
    "#     random_increments = np.random.normal(0, 1, size=n_step) * np.sqrt(dt)\n",
    "#     weiner_process = np.cumsum(random_increments)\n",
    "    \n",
    "#     # Stock price simulation\n",
    "#     stock_var = (mu - (sigma**2 / 2)) * time_vector\n",
    "#     s = s0 * np.exp(stock_var + sigma * weiner_process)\n",
    "    \n",
    "#     return s\n",
    "\n",
    "\n",
    "\n",
    "# def aobjective(params, real_prices, s0):\n",
    "#     \"\"\"Objective function for optimization.\"\"\"\n",
    "#     mu, sigma = params  # Unpack parameters\n",
    "#     gbm_prices = gbm(s0, mu, sigma, deltaT=len(real_prices), dt=1)\n",
    "#     return mean_squared_error(real_prices, gbm_prices)\n",
    "\n",
    "# def aoptimize_gbm(symbol: str, training_period: str, bin_length: int):\n",
    "#     \"\"\"\n",
    "#     Optimize μ and σ over multiple time bins, weighting recent periods more.\n",
    "#     \"\"\"\n",
    "#     # Fetch real stock data (past 5 years)\n",
    "#     stock_data = yf.download(symbol, period=training_period, interval=\"1d\")\n",
    "#     real_prices = stock_data[\"Close\"].dropna().values\n",
    "\n",
    "#     num_bins = len(real_prices) // bin_length\n",
    "#     weights = np.linspace(1, 2, num_bins)  # Increasing weights for recent bins\n",
    "\n",
    "#     mu_values, sigma_values, mses = [], [], []\n",
    "\n",
    "#     for i in range(num_bins):\n",
    "#         bin_prices = real_prices[i * bin_length : (i + 1) * bin_length]\n",
    "#         s0 = bin_prices[0]\n",
    "\n",
    "#         bounds = [(-0.3, 0.3), (0.001, 0.35)]\n",
    "\n",
    "#         result = differential_evolution(objective, bounds, args=(bin_prices, s0))\n",
    "#         best_mu, best_sigma = result.x\n",
    "#         best_mse = result.fun\n",
    "\n",
    "#         mu_values.append(best_mu)\n",
    "#         sigma_values.append(best_sigma)\n",
    "#         mses.append(best_mse)\n",
    "\n",
    "#     weight_sum = np.sum(weights)\n",
    "#     avg_mu = np.sum(np.array(mu_values) * weights) / weight_sum\n",
    "#     avg_sigma = np.sum(np.array(sigma_values) * weights) / weight_sum\n",
    "\n",
    "#     print(f\"\\nFinal Weighted Averages: μ = {avg_mu:.4f}, σ = {avg_sigma:.4f}\")\n",
    "\n",
    "#     return avg_mu, avg_sigma\n",
    "\n",
    "\n",
    "\n",
    "    # def filter_stocks(rolling_change_period): \n",
    "    # filtered_stocks = set()\n",
    "    # stocks = screen_stocks()\n",
    "\n",
    "    # for index, stock in stocks.iterrows():\n",
    "    #     try:\n",
    "    #         today_change, rolling_avg = get_rolling_price_change_avg(stock['ticker'], days=rolling_change_period)\n",
    "    #         current_price = get_current_stock_price(stock['ticker'])\n",
    "\n",
    "    #         # Skip if any value is None\n",
    "    #         if None in (today_change, rolling_avg, current_price):\n",
    "    #             print(f\"Skipping {stock['ticker']} due to missing data.\")\n",
    "    #             continue\n",
    "\n",
    "    #         # Apply filtering conditions\n",
    "    #         if (rolling_avg > 0.00): \n",
    "    #             filtered_stocks.add(stock['ticker'])\n",
    "\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Skipping {stock['ticker']} due to error: {e}\")\n",
    "    #         continue\n",
    "    \n",
    "    # return filtered_stocks\n",
    "\n",
    "    #def ORIGINAL_LOGIC_FOR _AUDITING_OPTIONS()\n",
    "    # simulation_attempts = 200\n",
    "    # optimizer_training_period = \"2y\"\n",
    "    # bin_length = 20\n",
    "    # rolling_change_period = 15\n",
    "    # expiration_date = datetime(year=2025, month=2, day=14) \n",
    "    # all_options = pd.DataFrame(columns=['symbol', 'expiration_date', 'option_type', 'strike_price', 'delta', 'gamma', 'rho', 'theta', 'vega', 'implied_volatility', 'ask_price', 'ask_size', 'bid_price', 'bid_size'])\n",
    "    # candidates = [\"AAPL\", \"AMD\"]\n",
    "    # # filter_stocks(rolling_change_period=rolling_change_period)\n",
    "\n",
    "    # # t-bill 3-month rate: 4.19%, inflation rate: 2.9% -> scaled to weekly\n",
    "    # risk_free_rate = (((1 + 0.0419) / (1 + 0.029)) ** (1/52) - 1) * 100\n",
    "\n",
    "    # print(candidates)\n",
    "\n",
    "    # for symbol in candidates:\n",
    "    #     option_chain = get_option_chain(api_key=api_key, secret_key=secret_key, ticker=symbol, expiration_date=expiration_date)\n",
    "    #     put_chain = option_chain[(option_chain['option_type'] == 'Put') & (option_chain['rho'].notna())].sort_values(by='strike_price', ascending=True)\n",
    "\n",
    "    #     if option_chain is None or option_chain.empty:\n",
    "    #         continue \n",
    "\n",
    "    #     price = get_current_stock_price(symbol)\n",
    "    #     optimized_mu, optimized_sigma = optimize_gbm(symbol=symbol, training_period=optimizer_training_period, bin_length=bin_length)\n",
    "\n",
    "    #     profitability_chances = []\n",
    "    #     percent_returns = []\n",
    "\n",
    "    #     for index, contract in put_chain.iterrows():\n",
    "    #         count = 0\n",
    "    #         strike_price = contract['strike_price']\n",
    "\n",
    "    #         for i in range(simulation_attempts):\n",
    "    #             prices = gbm(s0=price, mu=optimized_mu, sigma=optimized_sigma, \n",
    "    #                 deltaT=np.busday_count(datetime.today().date(), datetime.strptime(contract['expiration_date'], \"%Y-%m-%d\").date()), dt=1)  \n",
    "    #             if prices[-1] > strike_price:\n",
    "    #                 count += 1\n",
    "    #         profitability_chance = (count / simulation_attempts) * 100\n",
    "    #         profit = (contract['bid_price']*contract['bid_size'] + contract['ask_price']*contract['ask_size']) / (contract['ask_size'] + contract['bid_size'])\n",
    "    #         percent_return = (profit / (strike_price)) * 100\n",
    "\n",
    "    #         profitability_chances.append(profitability_chance)\n",
    "    #         percent_returns.append(percent_return)\n",
    "    #     put_chain['profitability_percent'] = profitability_chances\n",
    "    #     put_chain['percent_return'] = percent_returns\n",
    "    #     put_chain['expected_value'] = put_chain['profitability_percent'] * put_chain['percent_return']\n",
    "    #     put_chain['current_price'] = price\n",
    "    #     if put_chain['percent_return'].std() != 0:\n",
    "    #         put_chain['sharpe_ratio'] = (put_chain['percent_return'] - risk_free_rate) / put_chain['percent_return'].std()\n",
    "    #     else:\n",
    "    #         put_chain['sharpe_ratio'] = 0  # Avoid division by zero\n",
    "    #     all_options = pd.concat([all_options, put_chain], ignore_index=True, copy=False)\n",
    "\n",
    "\n",
    "# def gbm_vs_real_graph(symbol, mu, sigma, period):\n",
    "#     stock_data = yf.download(symbol, period=period, interval=\"1d\")\n",
    "#     real_prices = stock_data[\"Close\"].dropna().values\n",
    "#     time_steps = np.arange(len(real_prices))\n",
    "\n",
    "\n",
    "#     gbm_path = gbm(s0 = real_prices[0], mu=mu, sigma=sigma, deltaT=len(real_prices), dt=1)\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.plot(time_steps, real_prices, label=\"Real Prices\", color=\"blue\")\n",
    "#     plt.plot(time_steps, gbm_path, label=\"GBM Simulated\", linestyle=\"dashed\", color=\"red\")\n",
    "    \n",
    "#     plt.xlabel(\"Time (Days)\")\n",
    "#     plt.ylabel(\"Price\")\n",
    "#     plt.title(f\"GBM vs Real Prices for {symbol}\")\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "\n",
    "# def multithread_optimize_bin(bin_prices, bin_size, weights, i):\n",
    "#     s0 = bin_prices[0]\n",
    "\n",
    "#     # Define the bounds for optimization\n",
    "#     bounds = [(-0.3, 0.3), (0.001, 0.30)]\n",
    "\n",
    "#     # Run the optimizer for the bin\n",
    "#     result = differential_evolution(objective, bounds, args=(bin_prices, s0))\n",
    "#     best_mu, best_sigma = result.x\n",
    "#     best_mse = result.fun\n",
    "\n",
    "#     print(f\"Bin {i+1}: μ = {best_mu:.4f}, σ = {best_sigma:.4f}, MSE = {best_mse:.4f}\")\n",
    "#     return best_mu, best_sigma, best_mse\n",
    "\n",
    "# def multithread_optimize_gbm(symbol): \n",
    "    # \"\"\"\n",
    "    # Optimize μ and σ over multiple time bins, weighting recent periods more.\n",
    "    # \"\"\"\n",
    "    # # Fetch real stock data (past 2 years)\n",
    "    # stock_data = yf.download(symbol, period=\"2y\", interval=\"1d\")\n",
    "    # real_prices = stock_data[\"Close\"].dropna().values\n",
    "\n",
    "    # # Split into bins of 20 trading days\n",
    "    # bin_size = 20\n",
    "    # num_bins = len(real_prices) // bin_size\n",
    "    # weights = np.linspace(1, 2, num_bins)  # Increasing weights for recent bins\n",
    "\n",
    "    # # Initialize containers for results\n",
    "    # mu_values, sigma_values, mses = [], [], []\n",
    "\n",
    "    # # Use concurrent.futures for parallel processing of bins\n",
    "    # with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    #     futures = []\n",
    "    #     for i in range(num_bins):\n",
    "    #         bin_prices = real_prices[i * bin_size : (i + 1) * bin_size]\n",
    "    #         futures.append(executor.submit(optimize_bin, bin_prices, bin_size, weights, i))\n",
    "        \n",
    "    #     for future in concurrent.futures.as_completed(futures):\n",
    "    #         best_mu, best_sigma, best_mse = future.result()\n",
    "    #         mu_values.append(best_mu)\n",
    "    #         sigma_values.append(best_sigma)\n",
    "    #         mses.append(best_mse)\n",
    "\n",
    "    # # Compute weighted averages\n",
    "    # weight_sum = np.sum(weights)\n",
    "    # avg_mu = np.sum(np.array(mu_values) * weights) / weight_sum\n",
    "    # avg_sigma = np.sum(np.array(sigma_values) * weights) / weight_sum\n",
    "\n",
    "    # print(f\"\\nFinal Weighted Averages: μ = {avg_mu:.4f}, σ = {avg_sigma:.4f}\")\n",
    "\n",
    "    # return avg_mu, avg_sigma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
